This subdirectory contains the code for our audio-visual speech enhancement model, where we use background sounds (e.g., laughter, car engine, wind, etc.) sampled from AudioSet as noise in the mixture signal. The visual feature of the target speaker is used to guide the separation process. The demo/training/testing procedures are similar to audio-visual speech separation. The pre-trained models are shared [here](https://drive.google.com/drive/folders/1fwjDu3umZBvOJf0GRHMk5RfSg7Kd4WUc?usp=drive_link).
